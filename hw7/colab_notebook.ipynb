{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COs_-Y1xOKeJ"
   },
   "source": [
    "### Running Your Code in Colab\n",
    "\n",
    "We recommend you develop locally and then use Colab to run your code. You'll need to upload the code to drive.\n",
    "\n",
    "For experiments with a batch size greater than one, use the T4 GPU in order to see a *significant* speedup. This is crucial in order to run the experiments in a reasonable amount of time.\n",
    "\n",
    "Make sure to [download](https://drive.google.com/file/d/1mECKLG3NWH9uwFgAYRIdAKrABbTGkbVq/view?usp=sharing) the full training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0X2yjR1bI5C4"
   },
   "outputs": [],
   "source": [
    "# Mount your drive to access files in your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRpmUnlJJRyG"
   },
   "outputs": [],
   "source": [
    "# cd into the directory where your code is\n",
    "# e.g. %cd /content/drive/MyDrive/cmu/10-301/hw7/handout\n",
    "%cd /content/drive/MyDrive/<path to your code>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:51:30.764370Z",
     "start_time": "2024-11-17T20:51:30.759214Z"
    }
   },
   "source": [
    "# Set your data paths. Change this if the data is in a different location\n",
    "tiny_train_stories = 'data/tiny_train_stories.json'\n",
    "tiny_valid_stories = 'data/tiny_valid_stories.json'\n",
    "\n",
    "full_train_stories = '/Users/leesunny/PycharmProjects/10601 ML/hw7/hw7-4/handout/data/train_stories.json'\n",
    "full_valid_stories = '/Users/leesunny/PycharmProjects/10601 ML/hw7/hw7-4/handout/data/valid_stories.json'"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Whb8pdGOMU"
   },
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ign1vlA-c1lG"
   },
   "outputs": [],
   "source": [
    "!python test_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwfiNlt_GNpI"
   },
   "outputs": [],
   "source": [
    "!python rnn.py --train_data {tiny_train_stories} --val_data {tiny_valid_stories} --embed_dim 64 --hidden_dim 128 --train_losses_out train_loss.txt --val_losses_out valid_loss.txt --metrics_out metrics.txt --dk 32 --dv 32 --num_sequences 128 --batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y89FUa-7Mru"
   },
   "source": [
    "#### 5.1\n",
    "\n",
    "Uncomment the corresponding `embed_hidden_dims`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8msmm2XCKveG"
   },
   "outputs": [],
   "source": [
    "embed_hidden_dims = 64\n",
    "# embed_hidden_dims = 128\n",
    "# embed_hidden_dims = 256\n",
    "# embed_hidden_dims = 512\n",
    "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim {embed_hidden_dims} --hidden_dim {embed_hidden_dims} --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ4fn9YDAmiW"
   },
   "source": [
    "#### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vh5lsRTuApFD"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# batch_size = 64\n",
    "# batch_size = 128\n",
    "# batch_size = 256\n",
    "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3-FuxQlB8TI"
   },
   "source": [
    "#### 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtltQa_uB9a_"
   },
   "outputs": [],
   "source": [
    "num_sequences = 10000\n",
    "# num_sequences = 20000\n",
    "# num_sequences = 50000\n",
    "# num_sequences = 100000\n",
    "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences {num_sequences} --batch_size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iwe2VRiEjO2"
   },
   "source": [
    "#### 5.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rtMCKtcJEkZ0",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 512 --hidden_dim 512 --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 256 --dv 256 --num_sequences 250000 --batch_size 128"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T19:19:12.753818Z",
     "start_time": "2024-11-17T19:19:12.732079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import 必要的庫\n",
    "import torch\n",
    "from rnn_written import RNN, RNNLanguageModel  \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:54:01.995261Z",
     "start_time": "2024-11-17T20:54:01.811676Z"
    }
   },
   "cell_type": "code",
   "source": "!python /Users/leesunny/PycharmProjects/10601 ML/hw7/hw7-4/handout/rnn_written.py --train_data /Users/leesunny/PycharmProjects/10601 ML/hw7/hw7-4/handout/data/train_stories.json --val_data /Users/leesunny/PycharmProjects/10601 ML/hw7/hw7-4/handout/data/valid_stories.json --embed_dim 512 --hidden_dim 512 --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 256 --dv 256 --num_sequences 250000 --batch_size 128\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leesunny/PycharmProjects/10601 ML/.venv/bin/python: can't open file '/Users/leesunny/PycharmProjects/10601': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
